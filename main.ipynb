{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5112e5a6-b2ea-4f21-8cbf-764c7e1cff16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9687a232122d465b94ec46ba80ea445d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/69 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fcae679f6b47e3974587ca73602b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e333969d084d03a21ae4e163be8780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataloader_num_workers': 4, 'eval_strategy': 'epoch', 'fp16': True, 'gradient_accumulation_steps': 1, 'greater_is_better': True, 'learning_rate': 2e-05, 'load_best_model_at_end': True, 'logging_steps': 50, 'logging_strategy': 'steps', 'lr_scheduler_type': 'linear', 'max_grad_norm': 1.0, 'metric_for_best_model': 'eval_f1_macro', 'num_train_epochs': 5, 'output_dir': './mbert_sentiment', 'per_device_eval_batch_size': 64, 'per_device_train_batch_size': 32, 'save_strategy': 'epoch', 'seed': 42, 'warmup_ratio': 0.06, 'weight_decay': 0.01}\n",
      "AdamW {'lr': 2e-05, 'weight_decay': 0.01, 'eps': 1e-06, 'betas': (0.9, 0.999)}\n",
      "SGD {'lr': 0.0001, 'weight_decay': 0.01, 'nesterov': True, 'momentum': 0.95}\n",
      "[DBG-LIVE] epoch_start=0 global_step=0 wrapped=AcceleratedOptimizer base=AdamW lr=0.0 id=133135064372128 hyperparams={'lr': 0.0, 'betas': (0.9, 0.999), 'eps': 1e-06, 'weight_decay': 0.01, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'decoupled_weight_decay': True, 'initial_lr': 2e-05}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 01:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.084320</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.411111</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.042808</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.022843</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.022344</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.021859</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DBG-LIVE] epoch_start=1.0 global_step=3 wrapped=AcceleratedOptimizer base=AdamW lr=1.7142857142857142e-05 id=133135064372128 hyperparams={'lr': 1.7142857142857142e-05, 'betas': (0.9, 0.999), 'eps': 1e-06, 'weight_decay': 0.01, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'decoupled_weight_decay': True, 'initial_lr': 2e-05}\n",
      "[DBG-LIVE] epoch_start=2.0 global_step=6 wrapped=AcceleratedOptimizer base=AdamW lr=1.2857142857142859e-05 id=133135064372128 hyperparams={'lr': 1.2857142857142859e-05, 'betas': (0.9, 0.999), 'eps': 1e-06, 'weight_decay': 0.01, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'decoupled_weight_decay': True, 'initial_lr': 2e-05}\n",
      "Switching optimizer to SGD right after epoch 3 (next epoch will print SGD in your debug)\n",
      "[SWITCHED] base=SGD lr=0.0001\n",
      "[DBG-LIVE] epoch_start=3.0 global_step=9 wrapped=AcceleratedOptimizer base=SGD lr=0.0001 id=133135138571424 hyperparams={'lr': 0.0001, 'momentum': 0.95, 'dampening': 0, 'weight_decay': 0.01, 'nesterov': True, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}\n",
      "[DBG-LIVE] epoch_start=4.0 global_step=12 wrapped=AcceleratedOptimizer base=SGD lr=0.0001 id=133135138571424 hyperparams={'lr': 0.0001, 'momentum': 0.95, 'dampening': 0, 'weight_decay': 0.01, 'nesterov': True, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### BERT-BASE-MULTILINGUAL-CASED EVALUATION METRICS ###\n",
      "{'epoch': 5.0,\n",
      " 'eval_accuracy': 0.2857142857142857,\n",
      " 'eval_f1_macro': 0.225,\n",
      " 'eval_loss': 1.0926361083984375,\n",
      " 'eval_precision_macro': 0.21428571428571427,\n",
      " 'eval_recall_macro': 0.27777777777777773,\n",
      " 'eval_runtime': 0.1894,\n",
      " 'eval_samples_per_second': 110.871,\n",
      " 'eval_steps_per_second': 5.28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbd7cbea89247d78a306b2101c5d294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86eb1871dbad447a828b6246d3093c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/69 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e882d54d2e141ee9b2c8496aab02f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generic: A Modular Multi-Pipeline Framework for Probability Fusion Ensembles\n",
    "# Specific: Cross-Lingual Sentiment Analysis with Probability Fusion Ensembles: A Modular Multi-Pipeline Framework for Low-Resource Languages\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "from pathlib import Path\n",
    "from transformers import pipeline\n",
    "\n",
    "from src.config import *\n",
    "from src.metrics import evaluate_pipe\n",
    "from src import (\n",
    "    context,\n",
    "    helper,\n",
    "    sentiment, \n",
    "    utility, \n",
    ")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# helper.list_config()\n",
    "\n",
    "if App.HAS_GPU:\n",
    "    os.environ[\"MAMBA_USE_MAMBAPY\"] = Mamba.FORCE_CUDA\n",
    "\n",
    "if App.ACTION == \"INFER\":\n",
    "    sample_texts = [\n",
    "        \"Maganda ang serbisyo at mabilis ang delivery!\",\n",
    "        \"Sobrang pangit ng karanasan ko.\",\n",
    "        \"It was okay, nothing special.\",\n",
    "    ]\n",
    "    sentiment.infer(sample_texts, Mamba)\n",
    "    sentiment.infer(sample_texts, MBert)\n",
    "elif App.ACTION == \"ENSEMBLE\":\n",
    "        temps  = [1.1, 0.9]\n",
    "        weights = [0.4, 0.6]\n",
    "        ens = sentiment.ensemble([MBert, Mamba], temps, weights)\n",
    "        print(ens)\n",
    "elif App.ACTION == \"TRAIN\":\n",
    "    mbert_context = context.setup_pipeline(MBert, require_translation = False)\n",
    "    mbert_trainer = sentiment.train(mbert_context)\n",
    "\n",
    "    #xlmr_context = context.setup_pipeline(Xlmr, require_translation = False)\n",
    "    #xlmr_trainer = sentiment.train(xlmr_context)\n",
    "    \n",
    "    #mamba_context = context.setup_pipeline(Mamba, require_translation = True)\n",
    "    #mamba_trainer = sentiment.train(mamba_context)\n",
    "else:\n",
    "    raise ValueError(\"Invalid action.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a780c5-c36a-4c4e-8611-f81bf4ec337f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
