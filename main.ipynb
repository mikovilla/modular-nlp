{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5112e5a6-b2ea-4f21-8cbf-764c7e1cff16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c34c1f389a4560ad4610759bd78323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/69 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfdf2fc8447f401b9b8d7688b4265972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa94f9fdbda427abcc0ea5c5db5ffe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataloader_num_workers': 4, 'eval_strategy': 'epoch', 'fp16': True, 'gradient_accumulation_steps': 1, 'greater_is_better': True, 'learning_rate': 2e-05, 'load_best_model_at_end': True, 'logging_steps': 50, 'logging_strategy': 'steps', 'lr_scheduler_type': 'linear', 'max_grad_norm': 1.0, 'metric_for_best_model': 'eval_f1_macro', 'num_train_epochs': 5, 'output_dir': './mbert_sentiment', 'per_device_eval_batch_size': 64, 'per_device_train_batch_size': 32, 'save_strategy': 'epoch', 'seed': 42, 'warmup_ratio': 0.06, 'weight_decay': 0.01}\n",
      "[OPTIMIZER] epoch_start=0 global_step=0 wrapped=AcceleratedOptimizer base=AdamW lr=0.0 id=130028588329600 hyperparams={'lr': 0.0, 'betas': (0.9, 0.999), 'eps': 1e-06, 'weight_decay': 0.01, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'decoupled_weight_decay': True, 'initial_lr': 2e-05}\n",
      "[OPTIMIZER_GROUP]   group[0] {'lr': 0.0, 'betas': (0.9, 0.999), 'eps': 1e-06, 'weight_decay': 0.01, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'decoupled_weight_decay': True, 'initial_lr': 2e-05}\n",
      "[SCHEDULER]   scheduler_last_lr=[0.0]\n",
      "[PARAMS]   params_total=177,855,747 params_trainable=177,855,747\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 01:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.055290</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.525926</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.039355</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.003815</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.301587</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.002710</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.301587</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.001536</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINING_PERFORMANCE] epoch=1.0 tokens=0 time=0.78s tok/s=0.0 ex/s=0.00 peak_mem=3.33GiB lr=1.71e-05\n",
      "[EVALUATION_PERFORMANCE] tokens=16384 time=0.02s tok/s=790302.9 ex/s=6174.24\n",
      "[EVALUATION_PERFORMANCE] accuracy=0.5000 cost=$0.00 accuracy_per_$=810.99\n",
      "[OPTIMIZER] epoch_start=1.0 global_step=3 wrapped=AcceleratedOptimizer base=AdamW lr=1.7142857142857142e-05 id=130028588329600 hyperparams={'lr': 1.7142857142857142e-05, 'betas': (0.9, 0.999), 'eps': 1e-06, 'weight_decay': 0.01, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'decoupled_weight_decay': True, 'initial_lr': 2e-05}\n",
      "[OPTIMIZER_GROUP]   group[0] {'lr': 1.7142857142857142e-05, 'betas': (0.9, 0.999), 'eps': 1e-06, 'weight_decay': 0.01, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'decoupled_weight_decay': True, 'initial_lr': 2e-05}\n",
      "[SCHEDULER]   scheduler_last_lr=[1.7142857142857142e-05]\n",
      "[PARAMS]   params_total=177,855,747 params_trainable=177,855,747\n",
      "[TRAINING_PERFORMANCE] epoch=2.0 tokens=0 time=0.28s tok/s=0.0 ex/s=0.00 peak_mem=3.33GiB lr=1.29e-05\n",
      "[EVALUATION_PERFORMANCE] tokens=16384 time=0.02s tok/s=698326.3 ex/s=5455.67\n",
      "[EVALUATION_PERFORMANCE] accuracy=0.4000 cost=$0.01 accuracy_per_$=35.93\n",
      "[OPTIMIZER] epoch_start=2.0 global_step=6 wrapped=AcceleratedOptimizer base=AdamW lr=1.2857142857142859e-05 id=130028588329600 hyperparams={'lr': 1.2857142857142859e-05, 'betas': (0.9, 0.999), 'eps': 1e-06, 'weight_decay': 0.01, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'decoupled_weight_decay': True, 'initial_lr': 2e-05}\n",
      "[OPTIMIZER_GROUP]   group[0] {'lr': 1.2857142857142859e-05, 'betas': (0.9, 0.999), 'eps': 1e-06, 'weight_decay': 0.01, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'decoupled_weight_decay': True, 'initial_lr': 2e-05}\n",
      "[SCHEDULER]   scheduler_last_lr=[1.2857142857142859e-05]\n",
      "[PARAMS]   params_total=177,855,747 params_trainable=177,855,747\n",
      "Switching optimizer to SGD right after epoch 3 (next epoch will print SGD in your debug)\n",
      "[OPTIMIZER_SWITCH] base=SGD lr=0.0001\n",
      "[TRAINING_PERFORMANCE] epoch=3.0 tokens=0 time=0.30s tok/s=0.0 ex/s=0.00 peak_mem=3.33GiB lr=8.57e-06\n",
      "[EVALUATION_PERFORMANCE] tokens=16384 time=0.03s tok/s=538876.1 ex/s=4209.97\n",
      "[EVALUATION_PERFORMANCE] accuracy=0.5000 cost=$0.02 accuracy_per_$=22.50\n",
      "[OPTIMIZER] epoch_start=3.0 global_step=9 wrapped=AcceleratedOptimizer base=SGD lr=0.0001 id=130028582845616 hyperparams={'lr': 0.0001, 'momentum': 0.95, 'dampening': 0, 'weight_decay': 0.01, 'nesterov': True, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}\n",
      "[OPTIMIZER_GROUP]   group[0] {'lr': 0.0001, 'momentum': 0.95, 'dampening': 0, 'weight_decay': 0.01, 'nesterov': True, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}\n",
      "[SCHEDULER]   scheduler_last_lr=[8.571428571428571e-06]\n",
      "[PARAMS]   params_total=177,855,747 params_trainable=177,855,747\n",
      "[TRAINING_PERFORMANCE] epoch=4.0 tokens=0 time=0.17s tok/s=0.0 ex/s=0.00 peak_mem=4.00GiB lr=1.00e-04\n",
      "[EVALUATION_PERFORMANCE] tokens=16384 time=0.01s tok/s=1661336.7 ex/s=12979.19\n",
      "[EVALUATION_PERFORMANCE] accuracy=0.5000 cost=$0.03 accuracy_per_$=19.21\n",
      "[OPTIMIZER] epoch_start=4.0 global_step=12 wrapped=AcceleratedOptimizer base=SGD lr=0.0001 id=130028582845616 hyperparams={'lr': 0.0001, 'momentum': 0.95, 'dampening': 0, 'weight_decay': 0.01, 'nesterov': True, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}\n",
      "[OPTIMIZER_GROUP]   group[0] {'lr': 0.0001, 'momentum': 0.95, 'dampening': 0, 'weight_decay': 0.01, 'nesterov': True, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}\n",
      "[SCHEDULER]   scheduler_last_lr=[4.2857142857142855e-06]\n",
      "[PARAMS]   params_total=177,855,747 params_trainable=177,855,747\n",
      "[TRAINING_PERFORMANCE] epoch=5.0 tokens=0 time=0.28s tok/s=0.0 ex/s=0.00 peak_mem=4.00GiB lr=1.00e-04\n",
      "[EVALUATION_PERFORMANCE] tokens=16384 time=0.01s tok/s=1179481.4 ex/s=9214.70\n",
      "[EVALUATION_PERFORMANCE] accuracy=0.4000 cost=$0.03 accuracy_per_$=11.73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EVALUATION_PERFORMANCE] tokens=16384 time=0.01s tok/s=1404894.6 ex/s=10975.74\n",
      "[EVALUATION_PERFORMANCE] accuracy=0.3810 cost=$0.05 accuracy_per_$=8.39\n",
      "\n",
      "### BERT-BASE-MULTILINGUAL-CASED EVALUATION METRICS ###\n",
      "{'epoch': 5.0,\n",
      " 'eval_accuracy': 0.38095238095238093,\n",
      " 'eval_f1_macro': 0.3762483130904184,\n",
      " 'eval_loss': 1.0933195352554321,\n",
      " 'eval_precision_macro': 0.4358974358974359,\n",
      " 'eval_recall_macro': 0.40740740740740744,\n",
      " 'eval_runtime': 0.1692,\n",
      " 'eval_samples_per_second': 124.128,\n",
      " 'eval_steps_per_second': 5.911}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b234532b78124c68b79d160d45c0d385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e09c97dcef4d2ba18d2b10d8cf3d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/69 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a95cd89a7942d0ad0e750fe0c16361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generic: A Modular Multi-Pipeline Framework for Probability Fusion Ensembles\n",
    "# Specific: Cross-Lingual Sentiment Analysis with Probability Fusion Ensembles: A Modular Multi-Pipeline Framework for Low-Resource Languages\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "from pathlib import Path\n",
    "from transformers import pipeline\n",
    "\n",
    "from src.config import *\n",
    "from src.metrics import evaluate_pipe\n",
    "from src import (\n",
    "    context,\n",
    "    helper,\n",
    "    sentiment, \n",
    "    utility, \n",
    ")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "helper.list_config()\n",
    "\n",
    "if App.HAS_GPU:\n",
    "    os.environ[\"MAMBA_USE_MAMBAPY\"] = Mamba.FORCE_CUDA\n",
    "\n",
    "if App.ACTION == \"INFER\":\n",
    "    sample_texts = [\n",
    "        \"Maganda ang serbisyo at mabilis ang delivery!\",\n",
    "        \"Sobrang pangit ng karanasan ko.\",\n",
    "        \"It was okay, nothing special.\",\n",
    "    ]\n",
    "    sentiment.infer(sample_texts, Mamba)\n",
    "    sentiment.infer(sample_texts, MBert)\n",
    "elif App.ACTION == \"ENSEMBLE\":\n",
    "        temps  = [1.1, 0.9]\n",
    "        weights = [0.4, 0.6]\n",
    "        ens = sentiment.ensemble([MBert, Mamba], temps, weights)\n",
    "        print(ens)\n",
    "elif App.ACTION == \"TRAIN\":\n",
    "    mbert_context = context.setup_pipeline(MBert, require_translation = False)\n",
    "    mbert_trainer = sentiment.train(mbert_context)\n",
    "\n",
    "    #xlmr_context = context.setup_pipeline(Xlmr, require_translation = False)\n",
    "    #xlmr_trainer = sentiment.train(xlmr_context)\n",
    "    \n",
    "    #mamba_context = context.setup_pipeline(Mamba, require_translation = True)\n",
    "    #mamba_trainer = sentiment.train(mamba_context)\n",
    "else:\n",
    "    raise ValueError(\"Invalid action.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a780c5-c36a-4c4e-8611-f81bf4ec337f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
